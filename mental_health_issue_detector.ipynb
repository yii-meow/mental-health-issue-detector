{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8356470b",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088121ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import joblib\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6dd07",
   "metadata": {},
   "source": [
    "# Data Proprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c65623",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec597687",
   "metadata": {},
   "source": [
    "Load the data, and have an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3787719",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Suicide_Detection.csv')\n",
    "\n",
    "print(data.head(),\"\\n\")\n",
    "print(data.info(),\"\\n\")\n",
    "print(\"Shape: \",data.shape)\n",
    "\n",
    "# Convert string to 0/1 values\n",
    "data['is_suicide'] = data['class'].apply(lambda x: 1 if x == 'suicide' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686f9ed",
   "metadata": {},
   "source": [
    "The column 'Unnammed: 0' is a meaningless column at here, thus we can delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5cc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = 'Unnamed: 0', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6079c",
   "metadata": {},
   "source": [
    "Check is null value available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061ad8dd",
   "metadata": {},
   "source": [
    "### Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_words'] = data['text'].apply(lambda x: len(x.split()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b03e3",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106dee1",
   "metadata": {},
   "source": [
    "Proportion of suicide and non-suicide thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c2bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "classCount = data[\"is_suicide\"].value_counts()\n",
    "print(classCount)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Mental Health Issues')\n",
    "plt.pie(classCount, labels=['Suicide', 'Not Suicide'], autopct='%.0f%%')\n",
    "\n",
    "# Add a legend outside the pie chart\n",
    "plt.legend(title=\"Responses\", loc=\"upper left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Add a legend outside the pie chart\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8162e",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f895f",
   "metadata": {},
   "source": [
    "Lower Case, Remove Puncutuations, Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to lower case\n",
    "data['preprocessed_text'] = data['text'].str.lower()\n",
    "\n",
    "# Remove punctuations\n",
    "data['preprocessed_text'] = data['preprocessed_text'].str.replace(r'[^\\w\\s]+','',regex=True)\n",
    "\n",
    "# Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "data['preprocessed_text'] = data['preprocessed_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# Tokenize the words\n",
    "data['preprocessed_text'] = data['preprocessed_text'].apply(lambda x:nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a34111",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['preprocessed_text'] = data['preprocessed_text'].apply(lambda x: [lemmatizer.lemmatize(word,pos='v') for word in x])\n",
    "\n",
    "# ps = PorterStemmer()\n",
    "# data['preprocessed_text'] = data['preprocessed_text'].apply(lambda x: [ps.stem(i) for i in x])\n",
    "\n",
    "# Combine the words\n",
    "data['preprocessed_text'] = data['preprocessed_text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ad4f3",
   "metadata": {},
   "source": [
    "Check null values after preprocessing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46dcf8",
   "metadata": {},
   "source": [
    "Save preprocessed works to new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['preprocessed_text'] = data['preprocessed_text'].astype(str)\n",
    "data.to_csv('preprocessed.csv')\n",
    "\n",
    "preprocessed_data = pd.read_csv('preprocessed.csv')\n",
    "\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2292bba",
   "metadata": {},
   "source": [
    "### Words Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24ad0e6",
   "metadata": {},
   "source": [
    "show words commonly used when expressing suicidal thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f80e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud of suicidal thoughts\n",
    "preprocessed_data['preprocessed_text'] = preprocessed_data['preprocessed_text'].astype(str)\n",
    "\n",
    "suicidal_thoughts = \" \".join(preprocessed_data[preprocessed_data['is_suicide'] == 1]['preprocessed_text'])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "wordcloud = WordCloud(max_words = 300, height = 900, width = 1600, background_color='black',colormap='viridis').generate(suicidal_thoughts)\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f7cc2",
   "metadata": {},
   "source": [
    "show words ranking of suicidal thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f5d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_words_ranking = []\n",
    "for sentence in preprocessed_data[preprocessed_data['is_suicide'] == 1]['preprocessed_text'].to_list():\n",
    "    for word in sentence.split():\n",
    "        depression_words_ranking.append(word)\n",
    "        \n",
    "df = pd.DataFrame(Counter(depression_words_ranking).most_common(50),columns=['Word','Frequency'])\n",
    "\n",
    "sns.set_context('notebook')\n",
    "plt.figure(figsize=(18,8))\n",
    "sns.barplot(y=df['Word'], x=df['Frequency'],palette='summer')\n",
    "plt.title('Most commonly used words for suicidal thoughts')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae11993",
   "metadata": {},
   "source": [
    "Comparions of Original word & Preprocessed word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data[['text','preprocessed_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ddd453",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e769244d",
   "metadata": {},
   "source": [
    "For training the dataset and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf64652",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = preprocessed_data['preprocessed_text'],preprocessed_data['is_suicide']\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=50,max_features=5000)\n",
    "x = vectorizer.fit_transform(x).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=3)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ef331",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238bb6ba",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680e4d3",
   "metadata": {},
   "source": [
    "Naive bayes with voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_gaussian = GaussianNB()\n",
    "naive_bayes_bernoulli = BernoulliNB()\n",
    "naive_bayes_multinomial = MultinomialNB()\n",
    "\n",
    "VotingClassifiers = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('GaussianNB',naive_bayes_gaussian),\n",
    "        ('Bernoulli',naive_bayes_bernoulli),\n",
    "        ('Multinomial',naive_bayes_multinomial)\n",
    "    ],voting='soft'\n",
    ")\n",
    "\n",
    "VotingClassifiers.fit(X_train,y_train)\n",
    "\n",
    "nb_prediction = VotingClassifiers.predict(X_test)\n",
    "nb_confusion_matrix = confusion_matrix(y_test,nb_prediction)\n",
    "nb_accuracy = accuracy_score(y_test,nb_prediction)\n",
    "\n",
    "# Score for Training\n",
    "print(\"Training Score = \",VotingClassifiers.score(X_train,y_train))\n",
    "\n",
    "# Score for Testing\n",
    "print(\"Testing Score = \",VotingClassifiers.score(X_test,y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n\\nConfusion Matrix : \", nb_confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test,nb_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97dafbc",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30524b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(X_train,y_train)\n",
    "\n",
    "lr_prediction = lr_classifier.predict(X_test)\n",
    "lr_confusion_matrix = confusion_matrix(y_test,lr_prediction)\n",
    "lr_accuracy = accuracy_score(y_test,lr_prediction)\n",
    "\n",
    "# Score for Training\n",
    "print(\"Training Score = \",lr_classifier.score(X_train,y_train))\n",
    "\n",
    "# Score for Testing\n",
    "print(\"Testing Score = \",lr_classifier.score(X_test,y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix : \", lr_confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test,lr_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7b957",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# random_forest_classifier = RandomizedSearchCV(\n",
    "#     RandomForestClassifier(),\n",
    "#     {\n",
    "#         'n_estimators':[4,5],\n",
    "#         'criterion':['entropy'],\n",
    "#         'max_depth':range(1,4),'min_samples_split':range(2,5)\n",
    "#     }, random_state=10\n",
    "# )\n",
    "\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100,random_state=30)\n",
    "\n",
    "random_forest_classifier.fit(X_train,y_train)\n",
    "\n",
    "rf_prediction = random_forest_classifier.predict(X_test)\n",
    "rf_confusion_matrix = confusion_matrix(y_test,rf_prediction)\n",
    "rf_accuracy = accuracy_score(y_test,rf_prediction)\n",
    "\n",
    "# Score for Training\n",
    "print(\"Training Score = \",random_forest_classifier.score(X_train,y_train))\n",
    "\n",
    "# Score for Testing\n",
    "print(\"Testing Score = \",random_forest_classifier.score(X_test,y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix : \", rf_confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test,rf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4756460",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00854b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "svm_classifier.fit(X_train,y_train)\n",
    "\n",
    "svm_prediction = svm_classifier.predict(X_test)\n",
    "svm_confusion_matrix = confusion_matrix(y_test,svm_prediction)\n",
    "svm_accuracy = accuracy_score(y_test,svm_prediction)\n",
    "\n",
    "# Score for Training\n",
    "print(\"Training Score = \",svm_classifier.score(X_train,y_train))\n",
    "\n",
    "# Score for Testing\n",
    "print(\"Testing Score = \",svm_classifier.score(X_test,y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix : \", svm_confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test,svm_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be0f93",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29646916",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion='gini',splitter='random',min_samples_leaf=100,max_depth=6,random_state=0)\n",
    "decision_tree_classifier.fit(X_train,y_train)\n",
    "\n",
    "dt_prediction = decision_tree_classifier.predict(X_test)\n",
    "dt_confusion_matrix = confusion_matrix(y_test,dt_prediction)\n",
    "dt_accuracy = accuracy_score(y_test,dt_prediction)\n",
    "                             \n",
    "# Score for Training\n",
    "print(\"Training Score = \",decision_tree_classifier.score(X_train,y_train))\n",
    "                             \n",
    "# Score for Testing\n",
    "print(\"Testing Score = \",decision_tree_classifier.score(X_test,y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix : \", rf_confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test,rf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ffd1cf",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ev = pd.DataFrame({\n",
    "    'Model':['Naive Bayes','Random Forest','Decision Tree','Logistic Regression'],\n",
    "    'Accuracy':[nb_accuracy,nb_accuracy,lr_accuracy]\n",
    "})\n",
    "\n",
    "model_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e5237",
   "metadata": {},
   "source": [
    "Naive Bayes is the best fit model for the given dataset as it has the values,\n",
    "- Training Score: 0.9024567408018418\n",
    "- Testing Score =  0.8993723338551916"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aabce5",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098cd78",
   "metadata": {},
   "source": [
    "Save the model (Naive Bayes )with highest accuracy to a joblib file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(VotingClassifiers,'naive_bayes_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6536baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(word):\n",
    "    word = word.lower()\n",
    "    word = word.replace(r'[^\\w\\s]+','')\n",
    "    word = [word for word in word.split() if word not in (stop_words)]\n",
    "    word = ' '.join([ps.stem(i) for i in word])\n",
    "    return vectorizer.transform([word]).toarray()\n",
    "\n",
    "def mental_health_issue_detector(text):\n",
    "    print(\"Input = \",text)\n",
    "    processed_word = preprocess(text)\n",
    "    prediction = VotingClassifiers.predict(processed_word)\n",
    "    print(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17e078b",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ee95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_health_issue_detector(\"love\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
